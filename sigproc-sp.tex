% THIS IS SIGPROC-SP.TEX - VERSION 3.1
% WORKS WITH V3.2SP OF ACM_PROC_ARTICLE-SP.CLS
% APRIL 2009
%
% It is an example file showing how to use the 'acm_proc_article-sp.cls' V3.2SP
% LaTeX2e document class file for Conference Proceedings submissions.
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V3.2SP) *DOES NOT* produce:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) Page numbering
% ---------------------------------------------------------------------------------------------------------------
% It is an example which *does* use the .bib file (from which the .bbl file
% is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,
% you need to 'insert'  your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% Questions regarding SIGS should be sent to
% Adrienne Griscti ---> griscti@acm.org
%
% Questions/suggestions regarding the guidelines, .tex and .cls files, etc. to
% Gerald Murray ---> murray@hq.acm.org
%
% For tracking purposes - this is V3.1SP - APRIL 2009

\documentclass{acm_proc_article-sp}

\usepackage{auto-pst-pdf}

\begin{document}

\title{Robot Chameleons}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{5} 
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Apurv Suman\\
       \affaddr{Department of Computer Science}\\
       \affaddr{Yale University}\\
       \affaddr{New Haven, Connecticut 06520}\\
       \email{apurv.suman@yale.edu}
% 2nd. author
\alignauthor
Rebecca Marvin\\
       \affaddr{Department of Computer Science}\\
       \affaddr{Yale University}\\
       \affaddr{New Haven, Connecticut 06520}\\
       \email{rebecca.marvin@yale.edu}
\and 
% 3rd. author
\alignauthor Elena Corina Grigore\\
      \affaddr{Department of Computer Science}\\
       \affaddr{Yale University}\\
       \affaddr{New Haven, Connecticut 06520}\\
       \email{elena.corina.grigore@yale.edu}
% 4th. author 
\alignauthor Henny Admoni\\
      \affaddr{Department of Computer Science}\\
       \affaddr{Yale University}\\
       \affaddr{New Haven, Connecticut 06520}\\
       \email{henny.admoni@yale.edu} 
% 5th. author
\alignauthor Brian Scasselatti\\
      \affaddr{Department of Computer Science}\\
       \affaddr{Yale University}\\
       \affaddr{New Haven, Connecticut 06520}\\
       \email{brian.scasselatti@yale.edu}
}
\date{03 October 2014}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
This paper provides a sample of a \LaTeX\ document which conforms to
the formatting guidelines for ACM SIG Proceedings.
It complements the document \textit{Author's Guide to Preparing
ACM SIG Proceedings Using \LaTeX$2_\epsilon$\ and Bib\TeX}. This
source file has been written with the intention of being
compiled under \LaTeX$2_\epsilon$\ and BibTeX.

The developers have tried to include every imaginable sort
of ``bells and whistles", such as a subtitle, footnotes on
title, subtitle and authors, as well as in the text, and
every optional component (e.g. Acknowledgments, Additional
Authors, Appendices), not to mention examples of
equations, theorems, tables and figures.

To make best use of this sample document, run it through \LaTeX\
and BibTeX, and compare this source code with the printed
output produced by the dvi file.
\end{abstract}

\keywords{human-robot interaction, mimicry, chameleon effect} % NOT required for Proceedings

\section{Introduction}
We now live in a world where robots have become a part of our daily lives. Whether it is Siri in your pocket or the recently released Jibo in your home, robots have moved from a purely functional space to an interactive and social space. With this new movement, there is a pressing need to understand the social effects and impact of robots, particularly humanoid or anthropomorphized robots. Understanding the social effects of a robot will provide us with new information on how to better design robots for human interaction, how to structure human environments for robot presences, and how to anticipate the impact robots will have on our society moving forward. 

In trying to understand the social effects of robots, robotics must look to the field of psychology. Psychology can provide us a framework and a baseline to assess human-robot interaction. This is done by taking social constructs and effects from human-human interaction and mapping them to robots. This space of human-human effects mapped to human-robot interaction is still largely unexplored. In this study, we hope to elucidate a part of this space: automatic mimicry.

Behavioral mimicry- the automatic imitation of gestures, postures, mannerisms, and other motor movements, is pervasive in human interactions \cite{chartrand2013antecedents}. \textit{Automatic} mimicry in particular is often unconscious and unintentional. For example, studies have shown participants mimicking confederates tapping their feet or touching their faces during interactions, even without realizing they were doing so \cite{chartrand1999chameleon}. Furthermore, research has also shown that participants found confederates more likeable when the confederates mimicked the postures of the participants. There are several reasons why such a behavior exists. From a neurological standpoint, there exist certain parts of the brain responsible for this mimicry, known as mirror neurons or the ``mirror system'' in humans, first highlighted in macaques in 1992 at the University of Parma \cite{ehrenfeld2011reflections}. In fact an actual perception-behavior link exists behind automatic mimicry. This means that actions seen can trigger the mirror system in humans \cite{chartrand1999chameleon}. Beyond the neurology, there is a social component and possible evolutionary explanation for mimicry. Mimicry has been shown to create liking, empathy, and affiliation between interactants and act as the ``social glue'' that brings people together and bonds them \cite{chartrand2013antecedents}, \cite{lakin2003chameleon}. Also, research suggests that mimicry serves a prosocial communicative purpose \cite{bavelas1986show}, \cite{chartrand2013antecedents}.

We find several reasons as to why automatic mimicry should be studied. In the broadest sense, automatic mimicry is a thinly explored area of human-robot interaction that has a parallel in human-human interaction. Given that psychological research on mimicry has highlighted questions about mimicking the ``right'' people (i.e. ingroups vs. outgroups) \cite{bourgeois2008impact}, \cite{chartrand2013antecedents}, \cite{kavanagh2011s}, \cite{yabar2006implicit}, mimicry could highlight how humans view robots as social actors. Also, it has been observed that mimickers, and not just mimickees, have smoother interactions, smoother negotiations, more interpersonal trust, and more likability with their partners \cite{maddux2008chameleons}, \cite{stel2010mimicry}, \cite{swaab2011early}, so finding out if automatic mimicry exists in humans could give us information on how to shape interactions between humans and robots. From a practical standpoint, if robots can induce mimicry in humans, it provides us insight in to how a robot may induce behavior in humans within the real world as well. One can foresee possible concerns of a child or infant mimicking a robot in the home. One could also foresee issues regarding individuals mimicking a robot in public, perceiving the robot's actions as a sign of permissibility. All these new questions, however, rest on the assumption that a robot could in fact elicit mimicry in humans, an assumption we hope to probe in this study. Observing no mimicry or some kind of adverse social effect would also raise questions about why the perception-behavior link in human-human interaction does not extend to human-robot interaction.

Lastly, automated mimicry of physical behaviors is the first step in the larger phenomena of social contagion \cite{chartrand2013antecedents}, so understanding how human-robot interaction works for automated mimicry can act as a stepping stone to social contagion with human-robot interaction.

We hypothesize that:\\
\textbf{H1}	People who do not spontaneously exhibit a behavior will perform that behavior more after seeing a robot perform it.\\
\textbf{H2} People who do spontaneously exhibit a behavior will perform that behavior more after seeing a robot perform it.

We define spontaneous exhibition of a behavior to be performing a specified behavior for any period of time prior to observing the robot perform said behavior.

FINDING????

\section{Relevant Work}
There is evidence in research that suggests a robot could elicit automatic mimicry in humans. Oberman demonstrated through EEG that activation of the mirror neuron system in humans can occur through the perception of robot behavior, even without objects. This is significant as it informs us that the mirror neuron system and the perception-behavior link in humans is not uniquely limited to perceiving and reacting to human actions \cite{oberman2007eeg}. 

Bailenson successfully demonstrated that liking, rapport, and affiliation can be increased with mimicry even with a digital agent, which they showed using a virtual agent on a computer screen mimicking the head posture of the participants. This highlights one direction of the mimicry effect, in which a participant being mimicked has a more positive experience with a mimicker. The existence of this direction with a non-human agent suggests the possibility of the opposite direction, a human mimicking a non-human agent \cite{bailenson2005digital}. 

Riek conducted a study hoping to observe improved likability with an embodied robot (resembling an ape) mimicking head posture of a participant. Their study identified problems with assessing human-robot interactions using a survey and the difficulties of capturing and mimicking behaviors between humans and robots. Their work guided us in our planning of behaviors \cite{riek2010my}. Riek did find some support for more satisfactory interactions when facial expressions were mimicked by the same ape-like robot, although the findings were preliminary and in a pilot \cite{riek2008real}.

Hofree most significantly found that humans can spontaneously match facial expressions of an embodied android present in the room. Their study suggested that the salience of mimicry depended on how human-like the android presented is. This finding pushed our study to focus on a robot that minimized human-like features and emotions, allowing us to test on a more basic set of behaviors, devoid of expressions of emotions such as anger or happiness \cite{hofree2014bridging}. 

\section{Methods} 
In order to focus on \textit{automatic} mimicry, participants were given a task to complete while interacting the robot. Given the lack of research on robots inducing mimicry in humans, our study borrowed heavily from Chartrand \& Bargh's experimental design \cite{chartrand1999chameleon}. 

Participants alternated describing paintings with a Nao robot. Halfway through the trial, the Nao would assume a posture (either putting its hands behind its back or putting its hands on its hips) while continuing with the description of paintings. We measured the time the participant assumed the posture both before and after the Nao assumed the posture, making this a within-subjects study. The ``before'' period acted as the control while the ``after'' period acted as the observed variable.

This whole process was repeated with a different Nao for the same participant. The different Nao was brought in by the experimenter immediately after the conclusion of the first session. During the second session, the Nao performed whichever behavior the first Nao did not (either putting its hands behind its back or putting its hands on its hips). This gave us a larger data set of behaviors to observe and also helped us to control for participants who had existing tendencies to do one behavior or another.

Using two separate Naos came from the use of two different confederates in  the Chartrand \& Bargh study, which also used two different behaviors (touching the face and tapping the feet) \cite{chartrand1999chameleon}. The use of continuous postures rather than a discrete behavior was largely due to limitations of the robot, but we had little to reason to believe postures would not be effective behaviors given the extensive use of postures in mimicry research \cite{chartrand2013antecedents}. 

Our study aimed to minimize features that would increase the likelihood of mimicry such as goal to affiliate, which has been shown to increase mimicry \cite{chartrand2013antecedents}, \cite{drury2006effects}, \cite{lakin2003using}. The Nao's descriptions of the paintings were kept to be as simple as possible, with little to no emotion or interpretation \cite{hofree2014bridging}. The Nao also made no acknowledgement of the participants or their descriptions and the behaviors of hands behind back and hands on hips were chosen to minimize postural communication . 

\subsection{Robot Platform}
Nao is a 58-cm tall humanoid robot. Nao has 25 degrees of freedom, 2 cameras, 4 microphones, speakers, touch sensors, and an inertial measurement unit. For the study, Nao's legs were employed for standing up, Nao's arms were used to assume 1 of the 2 aforementioned postures, Nao's touch senors were used to start a script of behaviors, and Nao's speakers were used to voice the painting descriptions \cite{naodocumentation}. 

Nao is designed by Aldebaran on the Naoqi operating system. Python was used to program the Nao for the study. 

\subsection{Procedure}
Participants were first asked to fill out consent and video release forms. Participants were then randomly assigned to a group that saw hands behind back or hands on hips during the first session (with the other behavior occurring in the second session). Participants were then brought in to a closed 420cm x 300cm room. Participants faced the Nao at a distance of 180cm. The Nao stood on a platform raised 75cm off the ground. Next to the Nao stood next to a 68cm Apple iMac Display which ran Python scripts for the Nao's behaviors through a local area network connected to the Nao's head and displayed a PowerPoint presentation on Keynote. A GoPro was located at the back of the room and aimed at the participant's back. A camcorder was placed in the corner of the room facing the participant.

The participant was asked to read the first slide of directions while the experimenter turned on the cameras. Next, the experimenter started the PowerPoint and tapped the Nao's head sensor to start the Nao's Python scripts. The PowerPoint slides and scripts were synchronized. The Nao would turn its head to ``see'' the painting, turn back to the participant, and describe a painting (descriptions were pre-scripted) for 1 minute after which the participant was notified on-screen to do so as well. This continued for 3 paintings total. At this point, the Nao performed the assigned behavior for session 1 and maintained that posture for 3 more paintings. After 6 total paintings, the Nao returned to a crouch position and the experimenter replaced the Nao with a new one. The same process was repeated with 6 more paintings, except the other behavior was performed in session 2. 

After both sessions were completed, the participant completed a survey on Qualtrics, received \$5, and left.

\subsection{Data Collection}
Video of the participants were collected through a camcorder that captured the front of the participant and a GoPro that captured the back of the participant (this was necessary in order to validate any behaviors the participants portrayed behind their backs).

The videos were coded using ELAN 4.7.2. Both behaviors and variations of the behaviors were coded for. Participants also filled out a survey comprising of Likert Scale questions on intelligence and likability, short answer questions on what they liked/noticed about the trial, and demographic questions. Participants comprised of 49 Yale Undergraduates of which 43 were used in the final data analysis (6 participants did not qualify for the study or experienced a technical problem, such as losing internet connection, during the trial).

\section{Results}
This experiment yielded quantitative results from video coding of the recordings of participants and from self-reporting through a survey of Likert scale and short-answer questions. 

\textbf{Video Coding} We coded a participant putting hands on hips with 4 different designations and a participant putting hands behind back with 3 different designations. The different designations ensured we were able to cover all variations of the behaviors in the event they were displayed. For hands on hips the designations were two hands on hips, one hand on hip, hands in pockets, and hands in belt loops. We ultimately did not use hands in pockets because it did not accurately resemble the Nao's behavior, and we ultimately did not use hands in belt loops because it was very rarely performed by participants. For hands behind back the designations were two hands behind back, one hand behind back, and hands in back pockets. We ultimately did not use hands in bock pockets because it was very rarely performed by participants.
	
\textbf{Strict vs. Loose} For our analysis we broke both behaviors in to a strict and loose definition. For hands on hips, the strict definition matches the Nao's behavior of putting two hands on hips. The loose definition is a superset of this, with the participant exhibiting \textit{at least} one hand on hip. For hands behind back, the strict definition matches the Nao's behavior of putting two hands behind back. The loose definition is a superset of this, with the participant exhibiting \textit{at least} one hand behind back. Having a strict and loose interpretation allowed us to take into account participants who partially performed the behavior in our analysis. 

\textbf{Spontaneity} Participants were separated in to two different populations with different distributions. Those who performed the respective behavior at any point before the Nao did were considered spontaneous while those who did not were considered non-spontaneous.

\textbf{Non-Spontaneous Mimicry} The central question of this study is whether or not a robot can induce mimicry in humans. By definition, participants who did not spontaneously perform hands on hips or hands behind back had an average time performing those behaviors of 0 milliseconds. 

For the strict definition of hands on hips, non-spontaneous participants performed the behavior an average of 9280.71 milliseconds more after the Nao put its hands on its hips. A paired one-tailed t-test (n=34) found this result to be statistically significant with a p-value of 0.008. For the loose definition of hands on hips, non-spontaneous participants performed the behavior an average of 11592.13 milliseconds more after the Nao put its hands on its hips. A paired one-tailed t-test (n=32) found this result to be statistically significant with a p-value of 0.008. 

For the strict definition of hands behind back, non-spontaneous participants performed the behavior an average of 13420.10 milliseconds more after the Nao put its hands behind its back. A paired one-tailed t-test (n=30) found this result to be marginally significant with a p-value of 0.066. For the loose definition of hands behind back, non-spontaneous participants performed the behavior an average of 22292.48 milliseconds more after the Nao put its hands behind its back. A paired one-tailed t-test (n=29) found this result to be statistically significant with a p-value of 0.035.

\textbf{Spontaneous Mimicry} Our study identified that participants who spontaneously performed hands on hips or hands behind back independent of the robot doing so as a different population who would be impacted differently by the Nao performing a behavior they already were. This was confirmed in our survey data by numerous responses stating that the participant thought the robot was mimicking the participant's behavior. Because it is very difficult to pre-select participants who we know will spontaneously perform the behaviors, we had to rely on those who did within our overall population. As a result, we recognize the sample sizes are smaller and that are conclusions are weaker for people who do spontaneously perform a behavior.

For the strict definition of hands on hips, spontaneous participants performed the behavior an average of 90381 milliseconds before the Nao put its hand on its hips and an average of 42047 milliseconds after the Nao put its hand on its hips. A one-tailed paired t-test (n=9) found the difference of -48334 milliseconds to be statistically significant with a p-value of 0.025580944. For the loose definition of hands on hips, spontaneous participants performed the behavior an average of 80540.36 milliseconds before the Nao put its hand on its hips and an average of 39655.36 milliseconds after the Nao put its hand on its hips. A one-tailed paired t-test (n=11) found the difference of -40885 milliseconds to be statistically significant with a p-value of 0.030384716.

For the strict definition of hands behind back, spontaneous participants performed the behavior an average of 116665.08 milliseconds before the Nao put its hands behind its back and an average of 49043.77 milliseconds after the Nao put its hands behind its back. A one-tailed paired t-test (n=13) found the difference of -67621.30769 milliseconds to be statistically significant with a p-value of 0.040191878. For the loose definition of hands behind back, spontaneous participants performed the behavior an average of 135802.93 milliseconds before the Nao put its hands behind its back and an average of 73551.36 milliseconds after the Nao put its hands behind its back. A one-tailed paired t-test (n=14) found the difference of -62251.57 milliseconds to be marginally significant with a p-value of 0.051.

\textbf{Survey Results} Beyond providing us insight for our inferences in our discussion, we found no significant result for likability, intelligence, gender, or race and the performance of behaviors before or after the Nao performed them. Our lack of results here can be partially explained by lack of sufficient sample size for questions such as demographic analysis.

\textbf{Statistical Methods} Our determinations for statistical significance used the following guidelines and justifications. P-values less than 0.05 were deemed statistically significant while p-values between 0.05 and 0.1 were deemed marginally significant. Given that the experiment was run as a within-subjects study, a paired t-test was used. Finally, we used one-tailed t-tests because of our division of spontaneous and non-spontaneous participants based on their performance of a behavior being 0 or positive before the Nao performed the respective behavior. As a result, the direction for non-spontaneous participants performing behaviors after the Nao did so drew from a population mean that was positive while the direction for spontaneous participants performing behaviors after the Nao did so drew from a population mean that was negative.

\section{Discussion}

%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
This section is optional; it is a location for you
to acknowledge grants, funding, editing assistance and
what have you.  In the present case, for example, the
authors would like to thank Gerald Murray of ACM for
his help in codifying this \textit{Author's Guide}
and the \textbf{.cls} and \textbf{.tex} files that it describes.

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{sigproc}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
\end{document}
